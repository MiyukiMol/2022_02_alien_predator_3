{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f59d742",
   "metadata": {},
   "source": [
    "# Etude sur Alien vs Predator - épisode 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b73aaa",
   "metadata": {},
   "source": [
    "Développer un programme de vision par ordinateur capable de différencier avec précision un Alien d'un Predator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eacf95a",
   "metadata": {},
   "source": [
    "Contexte du projet\n",
    "\n",
    "L'épisode 2 a mis en évidence que la technique de \"data augmentation\" permet de diminuer de manière très efficace le surapprentissage mais n'améliore que très peu (dans notre exemple !) la performance de différenciation d'une image d'un alien d'une image d'un prédator. Dans l'épisode 3, nous allons utiliser la technique dite de \"transfer learning\" et plus particulièrement d'extractions de caractéristiques (\"features extraction\") pour améliorer les performances du programme de vision par ordinateur.\n",
    "\n",
    "エピソード2では、データ補強技術は過学習を減らすのに非常に有効であるが、エイリアン画像と捕食者画像の区別の性能は（我々の例では！）わずかに向上するのみであることが示された。第3話では、コンピュータビジョンのプログラムの性能を向上させるために、転移学習、より具体的には特徴抽出を利用します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a7a736",
   "metadata": {},
   "source": [
    "La procédure à suivre est la suivante :\n",
    "\n",
    "    Charger le modèle VGG-16 (mais qu'est-ce donc que ce VGG-16 ?) ;\n",
    "    Extraire les caractéristiques des images des jeux d'apprentissage, de validation et de test via VGG-16 ;\n",
    "    Entrainer un perceptron multi-couches avec le code Keras/TensorFlow suivant pour prédire à partir des caractéristiques extraites par VGG-16 la sortie (Alien ou Prédator) :\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(units=256, activation='relu', input_dim=4 * 4 * 512))\n",
    "\n",
    "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    Conclure.\n",
    "\n",
    "    VGG-16モデルをロードします（VGG-16とは一体何でしょうか？）\n",
    "    VGG-16により、トレーニングセット、検証セット、テストセットから画像特徴を抽出する。\n",
    "    VGG-16で抽出した特徴量から出力（エイリアンかプレデターか）を予測するために、以下のKeras/TensorFlowコードで多層パーセプトロンを学習させます。\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(units=256, activation='relu', input_dim=4 * 4 * 512))\n",
    "\n",
    "model.add(layers.Dense(units=1, activation=sigmoid'))\n",
    "\n",
    "    結論を出す。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7b084",
   "metadata": {},
   "source": [
    "Tâches optionnelles, pour les plus courageuses et les plus courageux d'entre vous :\n",
    "\n",
    "    Tester d'autres modèles que VGG-16 pour effectuer l'étape de \"features extraction\" ;\n",
    "    Tester d'autres modèles de Machine Learning (par exemple SVM) pour effectuer l'étape de supervision.\n",
    "\n",
    "オプションのタスク、勇敢なあなたへ。\n",
    "\n",
    "    VGG-16以外のモデルで「特徴抽出」ステップをテストする。\n",
    "    他の機械学習モデル（例：SVM）をテストして、監督ステップを実行する。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd5ee2",
   "metadata": {},
   "source": [
    "### 1 - import librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc36538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06bd0ba",
   "metadata": {},
   "source": [
    "### 2 - set option pour l'affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc4ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", None)\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "pd.set_option(\"max_row\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a8921",
   "metadata": {},
   "source": [
    "### 3 - charger des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb384ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'Data/'\n",
    "\n",
    "TRAINING_DIR = dataset_dir + 'train/'\n",
    "VALIDATION_DIR = dataset_dir + 'validation/'\n",
    "TEST_DIR = dataset_dir + 'Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9603267",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e880784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 494 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                            target_size = (150, 150),                                             \n",
    "                                            batch_size = 494,\n",
    "                                            class_mode=\"binary\",\n",
    "                                                        #seed=0\n",
    "                                              \n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b76a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                            target_size=(150, 150),\n",
    "                                            batch_size = 200,\n",
    "                                            class_mode=\"binary\",\n",
    "                                            #seed=0,\n",
    "                                           \n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef56676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(TEST_DIR,\n",
    "                                            target_size=(150, 150),\n",
    "                                            batch_size = 200,\n",
    "                                            class_mode=\"binary\",\n",
    "                                            #seed=0,                                           \n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732ec448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_generator[0][0]\n",
    "y_train=  train_generator[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39a345a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494, 150, 150, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07119763",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_generator[0][0]\n",
    "y_val = val_generator[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da95b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_generator[0][0]\n",
    "y_test = test_generator[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22d915d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifiction de VGG16\n",
    "model_all = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cca3da84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e94c428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (150, 150, 3)\n",
    "vgg = VGG16(input_shape = IMG_SHAPE, include_top = False,\n",
    "            weights=\"imagenet\")\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df31103",
   "metadata": {},
   "source": [
    "### Feature maps VGG16 pour Train / Test / Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb5d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = vgg.predict(train_generator[0][0]).reshape(494, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a06f8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_val = vgg.predict(val_generator[0][0]).reshape(200, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7439db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test = vgg.predict(test_generator[0][0]).reshape(200, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c2dc7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((494, 8192), (200, 8192))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train.shape, feature_val.shape,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18dbde92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efae2ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       ...,\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 4.737276, 0.      ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8bb775",
   "metadata": {},
   "source": [
    "### save features in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5132322",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('feature_train', feature_train)\n",
    "np.save('feature_val', feature_val)\n",
    "np.save('feature_test', feature_test)\n",
    "np.save('y_train', y_train)\n",
    "np.save('y_val', y_val)\n",
    "np.save('y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87d277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d2034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7a399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae643744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac0fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ab4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ca430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b53023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "625f8460",
   "metadata": {},
   "source": [
    "preprocess_fucntion : 各入力に適用される関数。この関数は他の変更が行われる前に実行される。この関数は３次元のNumpyテンソルを引数にとり、同じshapeのテンソルを出力するように定義する必要あり。\n",
    "\n",
    "各モデルにpreprocess_inputという便利な関数があります:モデルに適した値に正規化 ImageDataGenerator( preprocessing_function=preprocess_input, )\n",
    "\n",
    "https://qiita.com/tatsuya11bbs/items/f2008ba8c6f127ce7524 from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2cb73",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "https://github.com/tkeldenich/Computer_Vision_CNN_DataAugmentation/blob/main/Computer_Vision_CNN_DataAugmentation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca1a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57876d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
